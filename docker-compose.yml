services:
  spark-submit:
    build:
      context: ./
      dockerfile: Dockerfile
    container_name: spark-submit
    volumes:
      - ./src:/opt/jobs
    entrypoint: ["/bin/bash", "-lc"]
    command: >
      /opt/bitnami/spark/bin/spark-submit
      --packages
        org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.6.1,
        org.apache.hadoop:hadoop-aws:3.3.4
      --conf spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions
      --conf spark.sql.catalog.iceberg=org.apache.iceberg.spark.SparkCatalog
      --conf spark.sql.catalog.iceberg.catalog-impl=org.apache.iceberg.rest.RESTCatalog
      --conf spark.sql.catalog.iceberg.uri=http://rest:8183
      --conf spark.sql.catalog.iceberg.io-impl=org.apache.iceberg.hadoop.HadoopFileIO
      --conf spark.sql.catalog.iceberg.warehouse=s3a://iceberg/
      --conf spark.hadoop.fs.s3a.endpoint=http://minio:9000
      --conf spark.hadoop.fs.s3a.path.style.access=true
      --conf spark.hadoop.fs.s3a.access.key=minio
      --conf spark.hadoop.fs.s3a.secret.key=minio123
      --conf spark.hadoop.fs.s3a.connection.ssl.enabled=false
      --conf spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem
      /opt/jobs/main.py
